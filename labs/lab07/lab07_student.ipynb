{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Gradient Descent\n",
    "\n",
    "ER190 | Fall 2018\n",
    "\n",
    "Duncan Callaway\n",
    "\n",
    "GSI: Seigi Karasaki\n",
    "\n",
    "**Your Name**:\n",
    "\n",
    "**Collaborators**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will minimize average L1 loss analytically, numerically, and through gradient descent. After understanding the intuition behind gradient descent, we will write a function for L1 loss gradient descent and apply it to a small toy dataset, and then to the tips dataset from the Seaborn library. \n",
    "\n",
    "Run the following cells to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings; warnings.simplefilter('ignore', FutureWarning) # Seaborn triggers warnings in scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure nice plotting defaults - (this must be done in a cell separate from %matplotlib call)\n",
    "plt.style.use('seaborn')\n",
    "sns.set_context('talk', font_scale=1.4)\n",
    "plt.rcParams['figure.figsize'] = (10, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Absolute Loss (L1 Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we went over in lecture, average L1 loss takes in the absolute difference between each point and the prediction ($\\theta$). \n",
    "\n",
    "It is defined as:\n",
    "$\\begin{aligned}L(\\theta, \\textbf{y})&= \\frac{1}{n} \\sum_{i = 1}^{n} |y_i − \\theta| \\\\\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Absolute loss is known as L1 loss, and we will use the terms interchangeably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write `abs_loss()` which takes in a predicted y value and an observed y value and calculates the absolute loss (hint: there's a numpy function you'll probably find pretty handy). Then write `avg_absolute_loss()` which takes in a predicted y value and a dataset of observed y values, calculating the absolute loss for each and then finding the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_loss(y, y_obs):\n",
    "    return ...\n",
    "\n",
    "def avg_absolute_loss(y, data):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell and check to make sure the computation makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [5, 7, 8, 9]\n",
    "avg_absolute_loss(8, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the absolute loss to get a better sense of what's happening. Complete the following cell. We've provided for you `thetas` which serves as an array of guesses for the data. Our objective is to find the average absolute loss for each theta and then plot the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [5, 7, 8, 9]\n",
    "thetas = np.linspace(0, 10, 200)\n",
    "loss = ...\n",
    "... # Plot loss vs. theta here\n",
    "\n",
    "plt.vlines(data, -3, -2, colors=\"r\", linewidth=0.8, label=\"Observations\")\n",
    "plt.xlabel(r\"Choice for $\\theta$\")\n",
    "plt.ylabel(r\"Loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the plot, what value of theta minimizes our loss? Is our loss minimized the most by a single theta, or does it seem to be multiple thetas? Why do you think this is the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_YOUR ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat what we did before but instead choose our thetas to be very far from y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before we plot, a question: how do you think this will affect our loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>YOUR ANSWER HERE</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [5, 7, 8, 9]\n",
    "thetas = np.linspace(0, 100, 200)\n",
    "...\n",
    "\n",
    "plt.vlines(data, 0, 5, colors=\"r\", linewidth=2, label=\"Observations\")\n",
    "plt.xlabel(r\"Choice for $\\theta$\")\n",
    "plt.ylabel(r\"Loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, thetas far from y result in bad predictions and a bad fit, but only some loss. This is because L1 loss is less sensitive to outliers in comparison to other loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to minimize the average L1 loss analytically.\n",
    "\n",
    "In order to analytically find the theta that produces the $\\hat{\\theta}$, the $\\theta$ that minimizes the L1 loss, we need to get the partial derivative with respect to $\\theta$, that is $\\frac{\\partial}{\\partial \\theta} L(\\theta, \\textbf{y})$, and set it to zero. Unlike for L2 loss, we won't explicitly solve for $\\theta$, and you’ll see why as you work through the problem.\n",
    "\n",
    "\n",
    "Recall that the average L1 loss is defined to be:\n",
    "$\\begin{aligned}L(\\theta, \\textbf{y})&= \\frac{1}{n} \\sum_{i = 1}^{n} |y_i − \\theta| \\\\\\end{aligned}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find $\\frac{\\partial}{\\partial \\theta} L(\\theta, \\textbf{y})$ by hand and set it equal to zero. Show your work.\n",
    "\n",
    "If you're having trouble writing it out in markdown, write it on a piece of paper, take a (legible) photo of it, upload it online, and hyperlink it in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_YOUR ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "Why do we set the derivative equal to zero?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.3\n",
    "Based on your calculations in 2.1, you should have obtained $\\sum_{y_i < \\theta}(1) = \\sum_{y_i > \\theta}(1)$. What does it say about what $\\hat\\theta$ should be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s try out different values for theta, and see how much loss we get for each. Run the next three cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.25"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_absolute_loss(2, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_absolute_loss(7, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_absolute_loss(7.36, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1\n",
    "Now, let’s write a function called simple_minimize. All it does is take in a list/array of different theta values, finds the loss corresponding to each theta value, and returns the theta value that results in the least loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_minimize(loss_fun, observations, thetas):\n",
    "    losses = ... # Hint: You can use a list comprehension, or a couple more lines\n",
    "    return ... # Hint: return the theta corresponding to the minimum loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.368421052631579"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_minimize(avg_absolute_loss, data, np.linspace(0, 10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAG9CAYAAAB6TyBqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAADAQP8fqZ1YM4jOpAYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2520e857da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just run this cell.\n",
    "thetas = np.linspace(0, 10, 200)\n",
    "sparse_thetas = np.linspace(0, 10, 20)\n",
    "\n",
    "loss = avg_absolute_loss(thetas, data)\n",
    "sparse_loss = avg_absolute_loss(sparse_thetas, data)\n",
    "\n",
    "plt.plot(thetas, loss, label = \"L1 loss\")\n",
    "plt.plot(sparse_thetas, sparse_loss, 'r*', label = \"L1 loss\")\n",
    "plt.vlines(data, -5, -2, colors=\"r\", linewidth=0.8, label=\"Observations\")\n",
    "plt.xlabel(r\"Choice for $\\theta$\")\n",
    "plt.ylabel(r\"Loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This basic approach is incredibly inefficient, and suffers from two major flaws:\n",
    "\n",
    "1. If the minimum is outside our range of guesses, the answer will be completely wrong.\n",
    "\n",
    "2. Even if our range of gueseses is correct, if the guesses are too coarse, our answer will be inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we cannot minimize loss functions analytically, especially when our models get more complex. And as we have seen in the previous section, brute force minimization by just trying out a bunch of different theta values and seeing which one returns the least loss is also incredibly inefficient. \n",
    "\n",
    "Instead, we use a technique called gradient descent. You should have read [Ch.11 of the DS100 Textbook](https://www.textbook.ds100.org/ch/11/gradient_descent_define.html), but to remind you of the intuition:\n",
    "\n",
    "The slope of the tangent line tells us which direction to move $\\theta$ in order to decrease the loss. If the slope is negative, we want $\\theta$ to move in the positive direction. If the slope is positive, $\\theta$ should move in the negative direction. \n",
    "\n",
    "And mathematically, our formula is:\n",
    "\n",
    "$$\\theta^{(t+1)} = \\theta^{(t)} − \\alpha \\cdot \\frac{\\partial}{\\partial \\theta} L(\\theta^{(t)}, \\textbf{y})$$\n",
    "\n",
    "Where $ \\theta^{(t)}$ is the current estimate, $ \\theta^{(t+1)} $ is the next estimate, and $\\alpha$ is the learning rate, or step size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the partial derivative (gradient) of L1 loss, as calculated in 2.1. Using this formula, write a function that takes in a theta value and the observed data points, and returns the gradient of L1 loss at that theta. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial \\theta} L(\\theta, \\textbf{y})\n",
    "&= -\\frac{1}{n} \\sum_{i = 1}^{n} \\textbf{sign}(y_i - \\theta)\\\\\n",
    "&= -\\frac{1}{n} \\left( \\sum_{y_i < \\theta}(−1) + \\sum_{y_i = \\theta}(0) + \\sum_{y_i > \\theta}(1) \\right)\\\\\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grad_abs_loss(theta, dataset):\n",
    "    num_less = ...\n",
    "    num_greater = ...\n",
    "    n = ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function called minimize, which continues to find a new theta until the thetas converge. You only need to fill in the parts to find the new theta using the mathematical formula for gradient descent:\n",
    "\n",
    "$$\\theta^{(t+1)} = \\theta^{(t)} − \\alpha \\cdot \\frac{\\partial}{\\partial \\theta} L(\\theta^{(t)}, \\textbf{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def minimize(loss_fn, grad_loss_fn, dataset, alpha=0.2, progress=True):\n",
    "    '''\n",
    "    Uses gradient descent to minimize loss_fn. Returns the minimizing value of\n",
    "    theta_hat.\n",
    "    '''\n",
    "    theta = 0\n",
    "    loss = np.array([])\n",
    "    while True:\n",
    "        if progress:\n",
    "            print(f'theta: {theta:.2f} | loss: {loss_fn(theta, dataset):.2f}')\n",
    "        loss = ... # Append new loss to loss array\n",
    "        gradient = ...\n",
    "        new_theta = ...\n",
    "        \n",
    "        if len(loss) - len(np.unique(loss)) >= 10:\n",
    "            return new_theta\n",
    "        \n",
    "        theta = new_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see `minimize()` iteratively print each step in gradient descent and to find the minimizing theta for our small toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: 0.00 | loss: 14.66\n",
      "theta: 0.20 | loss: 14.46\n",
      "theta: 0.40 | loss: 14.26\n",
      "theta: 0.60 | loss: 14.06\n",
      "theta: 0.80 | loss: 13.86\n",
      "theta: 1.00 | loss: 13.66\n",
      "theta: 1.20 | loss: 13.46\n",
      "theta: 1.40 | loss: 13.26\n",
      "theta: 1.60 | loss: 13.06\n",
      "theta: 1.80 | loss: 12.86\n",
      "theta: 2.00 | loss: 12.66\n",
      "theta: 2.20 | loss: 12.46\n",
      "theta: 2.40 | loss: 12.26\n",
      "theta: 2.60 | loss: 12.06\n",
      "theta: 2.80 | loss: 11.86\n",
      "theta: 3.00 | loss: 11.66\n",
      "theta: 3.20 | loss: 11.46\n",
      "theta: 3.40 | loss: 11.26\n",
      "theta: 3.60 | loss: 11.06\n",
      "theta: 3.80 | loss: 10.86\n",
      "theta: 4.00 | loss: 10.66\n",
      "theta: 4.20 | loss: 10.46\n",
      "theta: 4.40 | loss: 10.26\n",
      "theta: 4.60 | loss: 10.06\n",
      "theta: 4.80 | loss: 9.86\n",
      "theta: 5.00 | loss: 9.66\n",
      "theta: 5.20 | loss: 9.46\n",
      "theta: 5.40 | loss: 9.26\n",
      "theta: 5.60 | loss: 9.06\n",
      "theta: 5.80 | loss: 8.86\n",
      "theta: 6.00 | loss: 8.66\n",
      "theta: 6.20 | loss: 8.46\n",
      "theta: 6.40 | loss: 8.26\n",
      "theta: 6.60 | loss: 8.06\n",
      "theta: 6.80 | loss: 7.86\n",
      "theta: 7.00 | loss: 7.66\n",
      "theta: 7.20 | loss: 7.46\n",
      "theta: 7.40 | loss: 7.26\n",
      "theta: 7.60 | loss: 7.06\n",
      "theta: 7.80 | loss: 6.86\n",
      "theta: 8.00 | loss: 6.66\n",
      "theta: 8.20 | loss: 6.46\n",
      "theta: 8.40 | loss: 6.26\n",
      "theta: 8.60 | loss: 6.06\n",
      "theta: 8.80 | loss: 5.86\n",
      "theta: 9.00 | loss: 5.66\n",
      "theta: 9.20 | loss: 5.46\n",
      "theta: 9.40 | loss: 5.26\n",
      "theta: 9.60 | loss: 5.06\n",
      "theta: 9.80 | loss: 4.86\n",
      "theta: 10.00 | loss: 4.66\n",
      "theta: 10.20 | loss: 4.46\n",
      "theta: 10.40 | loss: 4.26\n",
      "theta: 10.60 | loss: 4.06\n",
      "theta: 10.80 | loss: 3.86\n",
      "theta: 11.00 | loss: 3.66\n",
      "theta: 11.20 | loss: 3.46\n",
      "theta: 11.40 | loss: 3.26\n",
      "theta: 11.60 | loss: 3.06\n",
      "theta: 11.80 | loss: 2.86\n",
      "theta: 12.00 | loss: 2.66\n",
      "theta: 12.20 | loss: 2.50\n",
      "theta: 12.32 | loss: 2.43\n",
      "theta: 12.44 | loss: 2.36\n",
      "theta: 12.56 | loss: 2.28\n",
      "theta: 12.68 | loss: 2.21\n",
      "theta: 12.80 | loss: 2.14\n",
      "theta: 12.92 | loss: 2.12\n",
      "theta: 12.96 | loss: 2.11\n",
      "theta: 13.00 | loss: 2.10\n",
      "theta: 13.04 | loss: 2.09\n",
      "theta: 13.08 | loss: 2.08\n",
      "theta: 13.12 | loss: 2.08\n",
      "theta: 13.16 | loss: 2.07\n",
      "theta: 13.20 | loss: 2.06\n",
      "theta: 13.24 | loss: 2.05\n",
      "theta: 13.28 | loss: 2.04\n",
      "theta: 13.32 | loss: 2.04\n",
      "theta: 13.36 | loss: 2.03\n",
      "theta: 13.40 | loss: 2.02\n",
      "theta: 13.44 | loss: 2.01\n",
      "theta: 13.48 | loss: 2.00\n",
      "theta: 13.52 | loss: 2.00\n",
      "theta: 13.56 | loss: 1.99\n",
      "theta: 13.60 | loss: 1.98\n",
      "theta: 13.64 | loss: 1.97\n",
      "theta: 13.68 | loss: 1.96\n",
      "theta: 13.72 | loss: 1.96\n",
      "theta: 13.76 | loss: 1.95\n",
      "theta: 13.80 | loss: 1.94\n",
      "theta: 13.84 | loss: 1.93\n",
      "theta: 13.88 | loss: 1.92\n",
      "theta: 13.92 | loss: 1.92\n",
      "theta: 13.96 | loss: 1.91\n",
      "theta: 14.00 | loss: 1.90\n",
      "theta: 14.04 | loss: 1.89\n",
      "theta: 14.08 | loss: 1.88\n",
      "theta: 14.12 | loss: 1.88\n",
      "theta: 14.16 | loss: 1.87\n",
      "theta: 14.20 | loss: 1.86\n",
      "theta: 14.24 | loss: 1.85\n",
      "theta: 14.28 | loss: 1.84\n",
      "theta: 14.32 | loss: 1.84\n",
      "theta: 14.36 | loss: 1.83\n",
      "theta: 14.40 | loss: 1.82\n",
      "theta: 14.44 | loss: 1.81\n",
      "theta: 14.48 | loss: 1.80\n",
      "theta: 14.52 | loss: 1.80\n",
      "theta: 14.56 | loss: 1.79\n",
      "theta: 14.60 | loss: 1.78\n",
      "theta: 14.64 | loss: 1.77\n",
      "theta: 14.68 | loss: 1.76\n",
      "theta: 14.72 | loss: 1.76\n",
      "theta: 14.76 | loss: 1.75\n",
      "theta: 14.80 | loss: 1.74\n",
      "theta: 14.84 | loss: 1.73\n",
      "theta: 14.88 | loss: 1.72\n",
      "theta: 14.92 | loss: 1.72\n",
      "theta: 14.88 | loss: 1.72\n",
      "theta: 14.92 | loss: 1.72\n",
      "theta: 14.88 | loss: 1.72\n",
      "theta: 14.92 | loss: 1.72\n",
      "theta: 14.88 | loss: 1.72\n",
      "theta: 14.92 | loss: 1.72\n",
      "theta: 14.88 | loss: 1.72\n",
      "theta: 14.92 | loss: 1.72\n",
      "theta: 14.88 | loss: 1.72\n",
      "theta: 14.92 | loss: 1.72\n",
      "Minimizing theta: 14.879999999999942\n",
      "\n",
      "Wall time: 40 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "theta = minimize(avg_absolute_loss, grad_abs_loss, np.array([12.1, 12.8, 14.9, 16.3, 17.2]))\n",
    "print(f'Minimizing theta: {theta}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we learned earlier in the lab that the median is the best minimizer for the absolute loss. Run the following cell to confirm through gradient descent that this is indeed true. If it is true, nothing should print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert np.round(theta, 1) == np.median(np.array([12.1, 12.8, 14.9, 16.3, 17.2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on from our toy dataset, now we're going to run gradient descent from the tips dataset from the Seaborn library. Run the following cells below to load the dataset and find the minimizing theta through gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tips = sns.load_dataset('tips')\n",
    "tips['pcttip'] = tips['tip'] / tips['total_bill'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimizing theta: 15.43278688524595\n",
      "\n",
      "Wall time: 224 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "theta = minimize(avg_absolute_loss, grad_abs_loss, tips['pcttip'], progress=False)\n",
    "print(f'Minimizing theta: {theta}')\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.3\n",
    "Use a certain numpy function to find the minimizing theta of the tips dataset analytically. How does it compare to the minimizing theta found through gradient descent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "... # Replace with your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bibliography\n",
    "- DS100 - “Gradient Descent” - https://www.textbook.ds100.org/ch/11/gradient_descent_define.html \n",
    "- DS100 - “Absolute Loss” - https://www.textbook.ds100.org/ch/10/modeling_abs_huber.html\n",
    "- DS100 - “Models and Estimation” - http://www.ds100.org/fa18/assets/lectures/lec09/09-Models-and-Estimation-II.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Joshua Asuncion, Rebekah Tang\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
