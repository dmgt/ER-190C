{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ERG-190C] Homework 9: Model Selection\n",
    "\n",
    "---\n",
    "\n",
    "You've now had a chance to look deep into how different types of models are made, and the importance of judging how well a model performs on different features, and model tuning. However, given a dataset to analyze, how does one choose what kind of features are the most pertinent to the statistics we are trying to observe?\n",
    "\n",
    "We will find the answer to these questions using the `BechleLUR_2006_allmodelbuildingdata.csv` data file.\n",
    "\n",
    "---\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "ISLR Chapter 6\n",
    "\n",
    "- Bias-Variance Tradeoff\n",
    "- Ridge and Lasso Regression\n",
    "- Standardization\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[Introduction](#intro)<br>\n",
    "[1. The Data](#1)<br>\n",
    "[2. Bias-Variance Tradeoff and Ridge Regression\n",
    "](#2)<br>\n",
    "[3. Lasso Regression](#3)<br>\n",
    "[4. Putting it all Together + Standardization](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T18:50:14.728090Z",
     "start_time": "2018-08-13T18:50:08.632835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run this block.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "sns.set_context(\"talk\")\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name='intro'></a>\n",
    "\n",
    "Welcome to Homework 9! You are almost a full-fledged data scientist! You've now had a deeper look into how an algorithm decreases its error, and corrects itself to create a best-fit line to estimate future data that is has never seen, through formulas/methods such as gradient descent, regression, MSE, EDA, and more. It's now time to put everything you've learned to use.\n",
    "\n",
    "In the previous homework (hw8), we gave an introduction to choosing a model by showing when it is dangerous to overfit your training data, as well as looked into resampling through k-fold validation to avoid the danger of using too many parameters in our model. The ultimate lesson we learned from the previous homework is that having a flexible model (many parameters to tune) can cause strange calculations for estimating future data points.\n",
    "\n",
    "In this homework, to find the \"sweet-spot\" for which model we should choose for our estimation, we will examine the bias-variance tradeoff of multiple algorithms, as well as explore different regularization algorithms to avoid overfitting our model on specific parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Data\n",
    "\n",
    "You may recognize the data that we will be working with. That's because we used a smaller version of it in HW6 when we discussed linear regression in practice. Let's partly discuss the data again. \n",
    "\n",
    "* The data is an accumulation of GIS land-use characteristics from land-monitoring from the EPA, and in situ NO2 measurements from satellite sensors.\n",
    "* The goal of land-use regression (LUR) is to estimate outdoor air pollution geospatially across the contiguous United States.\n",
    "* The reason for the high number of data points is that the data keeps track of readings from monitors at a high resolution, up to ~30 meters.\n",
    "* Many of the columns are *strongly* colinear, because they are the same variable aggregated into 'buffers' of different size.  For example, impervious surface in a 100m buffer, within a 200m buffer, and so on.\n",
    "\n",
    "First, let's upload the data so it is Python-friendly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.1\n",
    "\n",
    "Read in the csv titled `BechleLUR_2006_allmodelbuildingdata.csv` as a dataframe into the variable `land_use`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 1.1\n",
    "land_use = ...\n",
    "land_use.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the first ten rows of the data. This will give an indication of the granularity as well as the ordering of the input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T18:50:24.791770Z",
     "start_time": "2018-08-13T18:50:24.754139Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "land_use.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good guess of the order of the data is based in the `State` and `Monitor_ID` columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a look at the data types in each column. If we're going to be throwing all the possible data at our model, we have to make sure that each column is able to be enumerated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T18:50:28.255153Z",
     "start_time": "2018-08-13T18:50:28.247349Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(land_use.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there are two variables which are not float variable types: `Monitor_ID` and `State`.  \n",
    "\n",
    "The monitor IDs in this data set are essentially randomly assigned, so there is no reason to use them.  \n",
    "\n",
    "As we discussed in class, we also have no reason to believe that NOx concentrations would be affected by state boundaries.  However we'll play around with keeping state information in the models we build, just to see how well the feature selection tools we're learning about perform.  \n",
    "\n",
    "Note!  If we knew state ID mattered we'd create *categorical* variables for each state, as we learned in class.  But in what's about to follow, instead, we're just going to assign numbers to each state.  Have faith: later on we'll see that the trusty lasso feature selection approach -- with good use of cross-validation -- isn't fooled by this meaningless feature.  \n",
    "\n",
    "Let's convert state strings to numeric values in what follows.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.2\n",
    "\n",
    "Create a new dictionary mapping each integer in [0-x] where $x$ is the number of unique state values in the `State` column (value), to its respective state string (key). Enumerate the categories in the `State` column correspondingly, and return the resulting dataframe with the new values.\n",
    "\n",
    "Hint: if you have a dict that uses entries in a data frame column as keys, you can access the values in the dict using the syntax `df[key_columm].map(dict_name)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 1.2\n",
    "states_dict = ...\n",
    "...\n",
    "land_use.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1.3\n",
    "\n",
    "Return a subset of the dataframe `land_use` in which contains only data for California. Save the resulting dataframe in a variable `land_use_ca`. This dataframe will be useful for later in the homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 1.3\n",
    "land_use_ca = ...\n",
    "land_use_ca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the data and its usage, read the pdf [here](/novotny.EST.2011.national.pdf). There are 135 possible parameters to deal with for our model here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bias-Variance Tradeoff and Ridge Regression<a name='2'></a>\n",
    "\n",
    "### Bias-Variance Tradeoff\n",
    "\n",
    "We know what it means to have high bias from our model. A model that outputs high bias is seen below from the previous homework:\n",
    "\n",
    "<img src='imgs/deg1.png' width=\"50%\" height=\"50%\"></img>\n",
    "\n",
    "So what does a model with high **variance** look like? Think about it - it should be a model with a very large range of values spread far away from the mean. In fact, we have seen this one before as well. Observe the calculations we did with 24 different parameters in the previous homework:\n",
    "\n",
    "<img src='imgs/deg24.png' width=\"50%\" height=\"50%\" ></img>\n",
    "\n",
    "Of course, neither of these models are ideal for future estimations, or estimations at locations where we don't have the desired observations. We want a model that will account for both of these issues and result in something between the spectrum. This is known as the **bias-variance tradeoff**. It is a tradeoff because a model can only have one or the other, or a little of both. To visualize the spectrum, study the figure below.\n",
    "\n",
    "<img src='imgs/bias_variance.png'></img>\n",
    "\n",
    "As the figure suggests, we can call a model with _high bias_ an _underfitted_ graph, while a _high variance_ model would be _overfitted_. Let's practice finding the balance between the two ends of the spectrum!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.1\n",
    "\n",
    "First, we need to identify the target variable, and visualize its relationship with some of the other variables. What is the variable that we are trying to estimate from our land-use regression (LUR)? Give one sentence for your reasoning. Use the code block below for scratch work.\n",
    "\n",
    "*Hint:  Keeping in mind that we are estimating NO2 levels from air pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch work goes here. This block will NOT be graded.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 2.1**: YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression\n",
    "\n",
    "Our feature matrix has a very high number of features in it (135 to be exact). It would be a big hassle to try and determine the weight of importance from each variable (that would take ages!). So how should we do it?\n",
    "\n",
    "Here is a general example: say you have a model with two features. For a normal linear regression, the result would look like...\n",
    "$$\\Large \\hat{y} = \\beta_1 x_i + \\beta_2 x_i^2$$\n",
    "\n",
    "However, there is the possibility such that one of the indicator variables does not have as much of an impact to the value of the predicted variable as originally intended when tested on unseen data. Conversely, there could also be similar variables that are not given equal weight. This would cause an overfitting problem later, meaning that the graph woudl have high variance. How would we fix this problem?\n",
    "\n",
    "Enter the **ridge regression ($L^2$ regularization)**. This formula takes the linear regression formula and adds a **regularization** or **penalty** term. Visually...\n",
    "\n",
    "$$\\Large \\hat{y} = \\beta_1 x_i + \\beta_2 x_i^2 + \\lambda \\cdot R_{L^2}(\\beta)$$\n",
    "\n",
    "where $\\large R_{L^2}(\\beta) = \\sum_{k=1}^p (\\beta_k)^2$ \n",
    "\n",
    "The higher the value of $\\large \\lambda$, the more a model is penalized for reaching outsider values. Essentially, we are decreasing variance, and increasing bias with our higher lambda value.\n",
    "\n",
    "*IMPORTANT NOTE: for the purposes of `sklearn`, the lambda value will typically be passed in as an argument `alpha` to an object constructor. Just know that alpha is the inverse of lambda, or $$\\large \\alpha = \\frac{1}{\\lambda}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what value of $\\large \\lambda$ would be a good sized penalty term? We need to check a few answers to find a good option for this term. What is a technique that we know that can will check for the \"best fit\" across different terms? You guessed it: cross-validation! Let's take a few steps to reach our final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.2\n",
    "\n",
    "Separate the `land_use` dataframe into train and test sets. The `X` term should be all of the variables in `land_use` with the exception of the target varible, and the `y` term should be the column of the target variable. The size of the test set should be 20% of the data. REMEMBER, we don't want the `Monitor_ID` variable in our data, so drop it before splitting the data.\n",
    "\n",
    "Hint: `train_test_split` is a useful library to import from sckikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T18:50:41.139386Z",
     "start_time": "2018-08-13T18:50:41.135035Z"
    }
   },
   "outputs": [],
   "source": [
    "# ANSWER 2.2\n",
    "from ... import ...\n",
    "X = ...\n",
    "y = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've split the data, let's take a look at the behavior of the **Ridge**. We're going to take a deeper look at the coefficients ($\\beta_i$) of each feature to see how the behavior changes between a normal linear regression and the regularized line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.3\n",
    "\n",
    "Import and create a Ridge regression model with an `alpha` value of 1. Fit the training data onto the model, then return a list of coefficients for each feature of the training data.\n",
    "\n",
    "Then, fit a `LinearRegression` model without the regularization involved. Print this array of coefficients as well to contrast its values with those of the Ridge model.\n",
    "\n",
    "*Note*: We're not cross-validating yet.\n",
    "\n",
    "*Hint*: Documentation for Ridge [here](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 2.3\n",
    "from ... import ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice the large amount of values very very close to zero in the array with the Ridge coefficients? In the context of the problem, we can say that any values that are very close to zero are features of the data that had low correlation scores with the data, meaning that adding those features to the model would be wasteful. Let's visualize this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.4\n",
    "\n",
    "Use your favorite visualization library to identify the statistically significant features in both the linear regression model and the Ridge model. Think about what kind of visualization would show this best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSSWER 2.4\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what have we done here specifically? The Ridge model has helped us identify the importance of some columns better than the linear regression model has. Although this change is small, it will help immensely in the long-run with minimizing our error.\n",
    "\n",
    "You just worked with a Ridge model, but is there an `alpha` value that would perform better than the one above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.5\n",
    "\n",
    "Create several ridge Regression models with the following alpha values: `[0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]`. You should use the same `X_train` and `y_train` from before.  Then, plot out the MSE scores, one for each alpha value, using your favorite visualization library.\n",
    "\n",
    "*Note*: There are two really important things we're not yet doing: normalizing our data, and cross validation.  Don't worry -- that's coming later!\n",
    "\n",
    "*Hint:* In the past, we've used an mse function that we defined on our own, but for this specific notebook, we'll be using the `sklearn` version of it instead. Here's the [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) for that specific function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 2.5\n",
    "from ... import ...\n",
    "alphas = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2.6\n",
    "\n",
    "Remember, alphas are the inverses of the $\\lambda$ values from before. With that in mind, what can you say about the optimal regularization parameter from your graph above? Write two sentences explaining which alpha was your choice, and explain what this means in the context of our model creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 2.6**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lasso Regression <a name='3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some drawbacks to using Ridge Regression that don't solve some specific problems:\n",
    "\n",
    "1. The ridge regression doesn't completely erase some features. It can get really close to 0, but will use all the features in the training data no matter what.\n",
    "2. This can still cause problems with model complexity and high variance.\n",
    "\n",
    "Perhaps there are cases in which you want to delete features altogether from your model. This is where the **lasso regression ($L^1$ regularization)** shines through. In equation form the Lasso Regression is as follows:\n",
    "\n",
    "$$\\Large \\hat{y} = \\beta_1 x_i + \\beta_2 x_i^2 + \\lambda \\cdot R_{L^1}(\\beta)$$\n",
    "\n",
    "where $\\large R_{L^1}(\\beta) = \\sum_{k=1}^p \\Big|\\beta_k\\Big|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.1\n",
    "\n",
    "Describe a situation in your model selection in which using a Lasso takes precedence over a Ridge model. One sentence should be enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 3.1**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.2\n",
    "\n",
    "Starting out small, let's repeat the steps we did above, this time for a Lasso Regression. Create a `Lasso` model with an alpha value of 1 and fit the `X_train` on the `y_train` dataset. Then, use any visualization library to plot the coefficients with their corresponding column against the linear model coefficients from question 2. Also, compute the MSE from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 3.2\n",
    "from ... import ...\n",
    "...\n",
    "\n",
    "lasso_mse =  ...\n",
    "print(lasso_mse)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice how many of these values now have coefficients of value 0? This looks very different from the previous graph when we were deterimining which features to train on. This is the ultimate difference between the Ridge and Lasso algorithms.\n",
    "\n",
    "However, which algorithm will be better suited in the end? This is what we will find out in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Putting it All Together + Standardization <a name='4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization (also known and normalization)\n",
    "\n",
    "Sometimes, we have columns of data with very wide range of values it can take. When using this regularization parameter (either Lasso or Ridge), we are scaling each column on a fixed amount, which has the possibility of actually decreasing the validity of a model.\n",
    "\n",
    "The simple solution for this is to **standardize** your columns.  (Later we'll call a sklearn function that has an option to normalize the data -- that's synonymous with standardization.)  Standardized random variables are distributed around zero-mean and unit variance, or in equation form:\n",
    "\n",
    "$$\\Large\n",
    "x_{\\text{standard}} = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "When using a regularization parameter, it is generally a good idea to always apply standardization. However, if you notice that your data has a large number of outliers, it may be better just to use the Lasso and the Ridge by itself. Why? Because standardizing these outliers will map the values into a much smaller interval, and will be difficult to resolve for later.\n",
    "\n",
    "**The upshot**: It's not a bad idea to fit models both with and without standardizing your variables, evaluate which performs better, and take that path.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.1\n",
    "\n",
    "Define a function `standardize_columns` that takes in a dataframe and returns a new one with all the columns standardized with 0 mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 4.1\n",
    "def standardize_columns(data):\n",
    "    '''\n",
    "    Input:\n",
    "      data (data frame): contains only numeric columns\n",
    "    Output:\n",
    "      data frame, the same data, except each column is standardized \n",
    "      to have 0-mean and unit variance\n",
    "    '''\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.2\n",
    "\n",
    "Create new dataframes `X_std` and `y_std` using the function you have defined right above. This will contain a dataframe in which all the columns of `X` and the data in `y` are now standardized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 4.2\n",
    "X_std = ...\n",
    "y_std = ...\n",
    "X_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV + Lasso/Ridge\n",
    "\n",
    "Now that you've gotten the chance to play with the \"penalty\" term of a simple regression, we have two ways in our toolbelt to combat the danger of overfitting our data: regularization and cross-validation (hw8). To further tune our model for maximum success rate, we'll combine the two ideas to find the ideal $\\lambda$ value.\n",
    "\n",
    "Fortunately, `sklearn` has made it incredibly easy to perform cross validation to find this ideal value: `LassoCV()` and `RidgeCV()`. We'll utilize this function in the following questions to find the ideal `alpha` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use cross-validation to choose the tuning parameter alpha, getting a range of values by using `np.linspace`. We can then find the alpha parameter, using the cross-validated ridge regression function, `RidgeCV()` from scikit-learn.  Note that we can also use `RidgeCV` to standardize our data (a.k.a. \"normalize\" the data) -- so tuning alpha, cross validation and normalization can all be done in one function call.  \n",
    "\n",
    "**Question 4.3:**\n",
    "\n",
    "Using `cv_alphas`, fit our training data to a `RidgeCV()` model. Use `neg_mean_squared_error` as the scoring parameter and normalize the regressors (think about why we should do this). Then assign the alpha value from the model to the variable `rcv_alpha`. With this new alpha value, fit a new ridge regression model with the training data and calculate the test MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ANSWER 4.3\n",
    "cv_alphas = np.linspace(0.0001, 100, 1000)\n",
    "\n",
    "...\n",
    "\n",
    "print(rcv_alpha)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4**: Also try fitting the model without normalizing your features.  Which performs better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 4.4**:  *YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the value of alpha that results in the smallest cross-validation error is the one assigned to `rcv_alpha`.\n",
    "\n",
    "Check to see if your MSE is comparable to the one we found in section 2. We normalized the data and cross-validated, so you'll likely get a different answer -- but it shouldn't be *wildly* different.\n",
    "\n",
    "Run the following cell to check the coefficient estimates, as well as a plot of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs = pd.Series(ridge_a.coef_, index=X.columns)\n",
    "print(coefs)\n",
    "coefs.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll move on to improving our lasso model. In the coefficient plot for lasso regression from earlier, note that many of the coefficients were 0. Depending on the choice of tuning parameter, some of the coefficients are exactly equal to zero. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Question 4.5:**\n",
    "\n",
    "Use `LassoCV()` to find the best alpha with the training data; set the `alpha` parameter to `cv_alphas` from earlier, and `max_iter` to 10000. Using this new alpha value, refit the original model (without CV) to the training data, and compute the mean squared error for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER 4.5\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be a lower MSE than the what you got from the model in section 3 as well as the ridge regression above, with alpha chosen by cross-validation.\n",
    "\n",
    "Lasso regression has a substantial advantage over ridge regression in that the resulting coefficient estimates are sparse. Run the following cell to see the coefficients for each feature and the plot as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_coefs = pd.Series(lasso.coef_, index=X.columns)\n",
    "print(l_coefs)\n",
    "plt.figure(figsize=(17, 5))\n",
    "plt.tick_params(axis='x', labelsize=7)\n",
    "l_coefs.plot('bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.6:** Now that we've seen both lasso and ridge regression in use, how do ridge regression and the lasso improve on ordinary least squares? In what cases would you expect ridge regression to perform better the lasso, and vice versa? Based on the last two plots, which would be easier for you to choose certain features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer 4.6***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparing your work to Novotny *et al* <a name='5'></a>\n",
    "This one's open-ended.  \n",
    "\n",
    "**Question 5.1**: Write some code to see if Lasso or Ridge deliver better models than Novotny et al found using their stepwise approach.  You can look in the Novotny paper to see which variables to grab from the data frame to put in the final model.  Note that 'Resident_' in your data corresponds to minor roads in the paper.  Also note that we do not have tree canopy data in our data set, so you can just omit it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER 5.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.2**: Once you've explored the performance of the Novotny model, comment on its differences with the other models you built.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer 5.2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION 5.2:**  We see the test MSE to be slightly worse than -- though extremely similar to -- lasso.  Interestingly, Ridge performs much worse in spite of the fact that many of the features are colinear (buffers of differing size are colinear).  This is because the number of features in the best model is truly small, and Ridge can't prune away the unneeded ones.  This generates variance in the test data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Submission\n",
    "\n",
    "Congrats, you're done with homework 9! \n",
    "\n",
    "In order to turn in this assignment, go to the toolbar and click **File** -> **Download as** -> **.html** and **.ipynb**. Submit the files through bCourses.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/06/a-comprehensive-guide-for-linear-ridge-and-lasso-regression/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Alex Nakagawa\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
